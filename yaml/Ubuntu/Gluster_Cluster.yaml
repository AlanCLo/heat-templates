HeatTemplateFormatVersion: '2012-12-12'

Description: "Template to create a small gluster cluster using the transient storage of the VM's.
              Although we ask for an availability zone it is resolutely ignored by the heat instance
              group resource. So it makes the location of this cluster a little bit hit and miss. Which
              means that it might not be as performant as desired. :("

Parameters:
  KeyName:
    Type: "String"
    Default: "nectar_dev"
    Description: "Name of an existing Nectar KeyPair (enables SSH access to the instances)"
  # We will limit the maximum number of instances to 10. Just because.
  InstanceCount:
    Type: "Number"
    Default: "2"
    MinValue: "1"
    MaxValue: "10"
    Description: "The number of instances to create"
  InstanceType:
    Type: "String"
    # You'd really want something like m1.xlarge, to get the larger sized transient storage.
    # but for development, this will do...
    Default: "m1.small"
    AllowedValues: [m1.small, m1.medium, m1.large, m1.xlarge, m1.xxlarge]
    Description: "Type of the instance to be created."
  AvailabilityZone:
    Type: "String"
    Default: "melbourne"
    AllowedValues: [ monash, melbourne-np, nova, melbourne, qld, melbourne-qh2, sa ]
    Description: "The NeCTAR zone in which the cluster is to run. Currently ignored..."
  ImageName:
    Type: String
    Description: Name of the image to use for the instance to be created
    Default: ubuntu-12.04
    AllowedValues: [ubuntu-12.04, ubuntu-12.10, ubuntu-13.10]

Mappings:
  InstanceId:
   'ubuntu-12.04': {ImageId: 884bfe1b-1c87-4a34-88da-69447b0ab8c6}
   'ubuntu-12.10': {ImageId: 50807835-eadf-4692-92e0-1b1ecc1cdfad}
   'ubuntu-13.10': {ImageId: 31c3848c-4d88-4e94-99cc-1e8e77c2c8cf}

Resources:

  ClusterSecurityGroup:
    Type: "AWS::EC2::SecurityGroup"
    Properties:
      GroupDescription: "Enable access between the machines in the cluster"
      SecurityGroupIngress:
        -
          IpProtocol: "icmp"
          FromPort: "-1"
          ToPort: "-1"
          CidrIp: "0.0.0.0/0"
        -
          IpProtocol: "tcp"
          FromPort: "22"
          ToPort: "22"
          CidrIp: "0.0.0.0/0"
        -
          IpProtocol: "tcp"
          FromPort: "111"
          ToPort: "111"
          CidrIp: "0.0.0.0/0"
        -
          IpProtocol: "udp"
          FromPort: "111"
          ToPort: "111"
          CidrIp: "0.0.0.0/0"
        -
          IpProtocol: "tcp"
          FromPort: "49100"
          ToPort: "49200"
          CidrIp: "0.0.0.0/0"
        -
          IpProtocol: "tcp"
          FromPort: "24007"
          ToPort: "24047"
          CidrIp: "0.0.0.0/0"

  ServerGroup:
    Type: "OS::Heat::InstanceGroup"
    Properties:
      # Availability zones here are both required and yet resolutely ignored.
      AvailabilityZones: [Ref: "AvailabilityZone"]
      LaunchConfigurationName:
        Ref: "ServerConfig"
      Size:
        Ref: "InstanceCount"
      AvailabilityZones:
        Fn::GetAZs: ""
      # We will add some metadata to each instance created.
      Tags:
        -
          Key: "Usage"
          Value: "Gluster"

  ServerConfig:
    Type: "AWS::AutoScaling::LaunchConfiguration"
    Properties:
      ImageId:
        Fn::FindInMap:
        - InstanceId
        - {Ref: ImageName}
        - ImageId
      InstanceType:
        Ref: "InstanceType"
      KeyName:
        Ref: "KeyName"
      SecurityGroups:
        - {Ref: ClusterSecurityGroup}
      NovaSchedulerHints:
        -
          Key: "part"
          Value: "long"
        -
          Key: "ready"
          Value: "short"
      UserData:
        Fn::Base64:
          Fn::Replace:
          - mount_directory: "/export/gvl-vol-replica"
          - |
            #!/bin/bash -x
            add-apt-repository ppa:semiosis/ubuntu-glusterfs-3.4
            apt-get update
            apt-get -y upgrade
            apt-get install -y glusterfs-server xfsprogs
            # get rid of annoying message
            echo "127.0.0.1     $HOSTNAME" | tee -a /etc/hosts
            # unmount the automatically mounted storage, reformat it and then remount it.
            umount /mnt
            mkfs.xfs -f -i size=512 /dev/vdb
            mkdir -p mount_directory
            mount /dev/vdb mount_directory

  MasterServer:
    Type: "AWS::EC2::Instance"
    Properties:
      # As the server group availability zone isn't implemented yet, we comment this one out
      #AvailabilityZone:
      #  Ref: "AvailabilityZone"
      # the following is a private image in which the heat-cfntools have been installed
      # you will have to install them into your own ubuntu instance if you want to make
      # use of the heat-cfntools
      ImageId:
        Fn::FindInMap:
        - InstanceId
        - {Ref: ImageName}
        - ImageId
      InstanceType:
        Ref: "InstanceType"
      KeyName:
        Ref: "KeyName"
      SecurityGroups:
        - {Ref: ClusterSecurityGroup}
      UserData:
        Fn::Base64:
          Fn::Replace:
          - mount_directory: "/export/gvl-vol-replica"
            instance_list:
              Fn::GetAtt:
                - "ServerGroup"
                - "InstanceList"
          - |
            #!/bin/bash -xv
            add-apt-repository ppa:semiosis/ubuntu-glusterfs-3.4
            apt-get update
            apt-get -y upgrade
            apt-get install -y glusterfs-server xfsprogs
            # get rid of annoying message shown when running sudo command
            echo "127.0.0.1     $HOSTNAME" | tee -a /etc/hosts
            # unmount the automatically mounted storage, reformat it and then remount it.
            umount /mnt
            mkfs.xfs -f -i size=512 /dev/vdb
            mkdir -p mount_directory
            mount /dev/vdb mount_directory
            # now to create the clusters
            export INSTANCES="instance_list"
            IFS=","
            for instance in $INSTANCES; do
              # assumption is that gluster peer probe will return error code if peer isn't set up yet.
              until gluster peer probe $instance; do echo "Probe failed : $?"; sleep 5; done
              # now wait for a while as we only want to proceed once the peer is up to speed...
              sleep 20
            done
            COMMAND_TAIL=""
            COUNTER=1
            for instance in $INSTANCES; do
              COMMAND_TAIL+=" $instance:/export/gvl-vol-replica/"
              COUNTER=$((COUNTER+1))
            done
            # need to add this machines IP address to the volume create command
            IP=`ifconfig  | grep 'inet addr:'| grep -v '127.0.0.1' | cut -d: -f2 | awk '{ print $1}'`;
            COMMAND_TAIL+=" $IP:/export/gvl-vol-replica/"
            COMMAND="gluster volume create gvl-volume replica $COUNTER transport tcp $COMMAND_TAIL force"
            eval $COMMAND
            gluster volume start gvl-volume

Outputs:
  IPs:
    Value:
      Fn::GetAtt:
        - "ServerGroup"
        - "InstanceList"
    Description: "The IP numbers for the slave servers..."
  ServerIP:
    Value:
      Fn::Join:
      - ''
      - - sudo mount -t glusterfs
        - Fn::GetAtt: [MasterServer, PublicIp]
        - :gvl-volume /mnt/glusterVol
        - /
    Description: "The command required to mount the server cluster..."